from dotenv import load_dotenv
import streamlit as st

from langchain.chat_models import ChatOpenAI
from langchain.chat_models import AzureChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain.callbacks import get_openai_callback

from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma

from langchain.document_loaders import PyPDFLoader
from langchain.document_loaders import TextLoader
from langchain.document_loaders import UnstructuredEPubLoader
from langchain.document_loaders import UnstructuredWordDocumentLoader
from langchain.document_loaders import UnstructuredMarkdownLoader
from langchain.document_loaders.csv_loader import CSVLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

import os
import tempfile
import chromadb


CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

AI_TEMPERATURE= 0

def extract_file_content(file):
    file_extension = os.path.splitext(file.name)[1]
    documents = []

    with tempfile.NamedTemporaryFile(delete=False) as temp_file:
        temp_file.write(file.read())
        temp_file_name = temp_file.name

    if file_extension == ".pdf":
        documents = extract_pdf_content(temp_file_name)
    elif file_extension in (".xls", ".xlsx", ".csv"):
        documents = extract_csv_content(temp_file_name)
    elif file_extension in (".docx"):
        documents = extract_word_content(temp_file_name)
    elif file_extension == ".epub":
        documents = extract_epub_content(temp_file_name)
    elif file_extension == ".txt":
        documents = extract_txt_content(temp_file_name)

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size = CHUNK_SIZE,
        chunk_overlap  = CHUNK_OVERLAP,
        length_function = len,
    )
    chunks = text_splitter.split_documents(documents)

    temp_file.close()
    os.remove(temp_file_name)

    return chunks


def extract_pdf_content(file_path):
    loader = PyPDFLoader(file_path)
    return loader.load_and_split()

def extract_word_content(file_path):
    loader = UnstructuredWordDocumentLoader(file_path, mode="elements")
    return loader.load_and_split()

def extract_csv_content(file_path):
    loader = CSVLoader(file_path)
    return loader.load_and_split()

def extract_epub_content(file_path):
    loader = UnstructuredEPubLoader(file_path, mode="elements")
    return loader.load_and_split()

def extract_md_content(file_path):
    loader = UnstructuredMarkdownLoader(file_path, mode="elements")
    return loader.load_and_split()

def extract_txt_content(file_path):
    loader = TextLoader(file_path, encoding="utf8")
    return loader.load_and_split()

def embedding_2_vectorDB(embeddings,contents):
    ABS_PATH = os.path.dirname(os.path.abspath(__file__))
    DB_DIR = os.path.join(ABS_PATH, "db")

    # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
    if not os.path.exists(DB_DIR):
        os.mkdir(DB_DIR)

    client_settings = chromadb.config.Settings(
        chroma_db_impl="duckdb+parquet",
        persist_directory=DB_DIR,
        anonymized_telemetry=False,
    )

    vectorstore = Chroma(
        collection_name="langchain_store",
        embedding_function=embeddings,
        client_settings=client_settings,
        persist_directory=DB_DIR,
    )

    # å­˜å‚¨å‘é‡è‡³æ•°æ®åº“
    vectorstore.add_documents(documents=contents, embedding=embeddings)
    vectorstore.persist()
    # print("vectorstore: \n",vectorstore)

    return vectorstore


def load_openAILLM():
    os.environ["OPENAI_API_KEY"] = os.environ['API_KEY']
    os.environ["OPENAI_API_BASE"] = os.environ['API_BASE']

    chat = ChatOpenAI(
        openai_api_base = os.environ['API_BASE'],
        openai_api_key = os.environ['API_KEY'],
        temperature=AI_TEMPERATURE)
    
    embeddings = OpenAIEmbeddings()
    
    return chat,embeddings

def load_azureLLM():
    os.environ["OPENAI_API_TYPE"] = "azure"
    os.environ["OPENAI_API_BASE"] = os.environ['API_BASE']
    os.environ["OPENAI_API_KEY"] = os.environ['API_KEY']
    os.environ["OPENAI_API_VERSION"] = "2023-03-15-preview"

    AZURE_DEPLOYMENT_NAME = os.environ['DEPLOYMENT_NAME_CHAT']
    AZURE_DEPLOYMENT_NAME_EMBEDDING = os.environ['DEPLOYMENT_NAME_EMBEDDING']

    # åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹
    chat = AzureChatOpenAI(
        openai_api_type= "azure",
        openai_api_base=os.environ['API_BASE'],
        openai_api_key=os.environ['API_KEY'],
        openai_api_version="2023-03-15-preview",
        deployment_name=AZURE_DEPLOYMENT_NAME,
        temperature=AI_TEMPERATURE)

    # åˆå§‹åŒ–å‘é‡æ¨¡å‹
    embeddings = OpenAIEmbeddings(deployment = AZURE_DEPLOYMENT_NAME_EMBEDDING,chunk_size=1)
    
    return chat,embeddings

def load_LLM():
    ai_type = os.environ["API_TYPE"]
    if ai_type == 'azure':
        chat,embedding = load_azureLLM()
    else:
        chat,embedding = load_openAILLM()

    return chat,embedding

    
def ask(chat,knowledge_db):
    user_question = st.text_input("è¯·å‘æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©æ‚¨çš„ï¼Ÿ")
    if user_question:
      # åœ¨å‘é‡æ•°æ®åº“ä¸­æŸ¥æ‰¾ç›¸ä¼¼åº¦æœ€é«˜çš„TopNç»“æœ
      docs = knowledge_db.similarity_search(user_question)
      
      # èšåˆtopNç›¸ä¼¼åº¦çš„embddingsï¼Œå‘llmæé—®
      chain = load_qa_chain(chat, chain_type="stuff")
      with get_openai_callback() as cb:
        response = chain.run(input_documents=docs, question=user_question)
        # print(cb)
      
      ## å›æ˜¾
      st.write(response)
      st.write(cb)

def main():
    load_dotenv()
    st.set_page_config(page_title="ChatDocument")
    st.header("ChatDocument ä¸æ–‡æ¡£äº¤æµ ğŸ’¬")

    # upload file
    uploaded_file = st.file_uploader("ä¸Šä¼ æ–‡æ¡£", type=["pdf", "epub", "txt", "docx", ".xls", ".xlsx", ".csv"])

    if uploaded_file is not None:
      # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨ä¸åŒçš„è§£æå‡½æ•°
      st.write("æ­£åœ¨æå–å†…å®¹ï¼Œè¯·ç¨ç­‰...")
      chunks = extract_file_content(uploaded_file)

    #   st.write("æå–çš„å†…å®¹å¦‚ä¸‹ï¼š")
    #   st.write(chunks)

      # åŠ è½½æ¨¡å‹
      chat,embeddings = load_LLM()

      st.write("æ­£åœ¨å‘é‡åŒ–å­˜å‚¨å†…å®¹......")
      knowledge_db = embedding_2_vectorDB(embeddings,chunks)

      # ç”¨æˆ·äº¤äº’æé—®
      ask(chat,knowledge_db)




if __name__ == '__main__':
    main()
